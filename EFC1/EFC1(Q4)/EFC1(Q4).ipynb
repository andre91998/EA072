{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFC1 (Q4): Convolutional Neural Network, Keras Framework, Tensorflow Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we start out with a basic convolutional neural netowrk with two convolutional layers, each with a 3x3 kernel and RELU as their activation function. On top of that another fully connected hidden layer with 128 neurons and 0.5 dropout. The code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\"\n",
    "%-----------------------------------------------------------------------------%\n",
    "%Author: André Barros de Medeiros\n",
    "%Date:09/16/2019\n",
    "%Copyright: free to use, copy, and modify\n",
    "%Description: Convolutional Network to classify MNIST dataset images\n",
    "%Important: Activation Function: RELU (first layer)\n",
    "%           Optimizer Algorithm: ADAM\n",
    "%           Loss Function: Cross Entropy\n",
    "%\n",
    "%           Loss: 0.0665 / Accuracy: 0.9811\n",
    "%-----------------------------------------------------------------------------%\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "epoch=5\n",
    "conv1=32\n",
    "conv2=64\n",
    "kernel= [3,3]\n",
    "pool=[2,2]\n",
    "dropout1=0.25\n",
    "neurons=128\n",
    "dropout2=0.5\n",
    "\n",
    "bestAccuracy=[2,0,0,0,0,0,0,0,0.2]\n",
    "\n",
    " \n",
    "print(\"\\nepoch: \" + str(epoch)+\"\\n Convolution 1: \"+str(conv1)+\" with kernel: \"+str(kernel) +\"\\n Convolution 2: \"+str(conv2)+\" with kernel: \"+str(kernel)+\" and MaxPooling pool size: \"+str(pool)+\" and dropout: \"+str(dropout1)+ \"\\n Fully connected layer with: \"+str(neurons)+\" and dropout: \"+str(dropout2)+\"\\n\")\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][pixels]\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "evaluation = model.evaluate(x_test, y_test)\n",
    "print( \"\\nAcurracy is :\" + str(evaluation[1])+\"\\n\")\n",
    "if evaluation[1] > bestAccuracy[4]:\n",
    "    bestAccuracy = [2, epoch, conv1, conv2, kernel[1], pool[1], dropout1, neurons, dropout2, evaluation[0], evaluation[1]]\n",
    "    print(\"\\n New Best Accuracy \\n\")\n",
    "model_json = model.to_json()\n",
    "\n",
    "json_file = open(\"model_CNN.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "model.save_weights(\"model_CNN.h5\")\n",
    "print(\"Model saved to disk\")\n",
    "os.getcwd()\n",
    "\n",
    "f=open(\"ConvInitial.txt\",\"a+\")\n",
    "f.write(\"\\n\"+str(bestAccuracy[0])+\" ; \"+str(bestAccuracy[1])+\" ; \"+str(bestAccuracy[2])+\" ; \"+str(bestAccuracy[3])+\" ; \"+str(bestAccuracy[4])+\" ; \"+str(bestAccuracy[5])+\" ; \"+str(bestAccuracy[6])+\" ; \"+str(bestAccuracy[7])+\" ; \"+str(bestAccuracy[8])+\" ; \"+str(bestAccuracy[9])+\" ; \"+str(bestAccuracy[10]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the network 4 times to calculate an average loss and average accuracy, obtaining:\n",
    "\n",
    "Average Loss: 0.031909425\n",
    "Average Accuracy: 0.989825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to improve the netowork. To do so, we adopt a \"trial and error\" approach and with a for loop, train several networks with different parameters. In the code below you will see another convolutional layer was added and the following parameters were experimented with: size of the convolution and the layer's dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\"\n",
    "%-----------------------------------------------------------------------------%\n",
    "%Author: André Barros de Medeiros\n",
    "%Date:09/16/2019\n",
    "%Copyright: free to use, copy, and modify\n",
    "%Description: Convolutional Network to classify MNIST dataset images\n",
    "%Important: Activation Function: RELU (first layer)\n",
    "%           Optimizer Algorithm: ADAM\n",
    "%           Loss Function: Cross Entropy\n",
    "%\n",
    "%           Loss: 0.0665 / Accuracy: 0.9811\n",
    "%-----------------------------------------------------------------------------%\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "epoch=5\n",
    "conv1=32\n",
    "conv2=64\n",
    "kernel= [3,3]\n",
    "pool=[2,2]\n",
    "dropout1=0.25\n",
    "conv3=[32,64]\n",
    "dropout2=[0.3,0.5]\n",
    "neurons=128\n",
    "dropout3=0.5\n",
    "\n",
    "bestAccuracy=[2,0,0,0,0,0,0,0,0,0,0,0,0.2]\n",
    "\n",
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        print(\"\\nepoch: \" + str(epoch)+\"\\n Convolution 1: \"+str(conv1)+\" with kernel: \"+str(kernel) +\"\\n Convolution 2: \"+str(conv2)+\" with kernel: \"+str(kernel)+\" and MaxPooling pool size: \"+str(pool)+\" and dropout: \"+str(dropout1)+\"\\n Convolution 3: \"+str(conv3[i])+\" with kernel: \"+str(kernel)+\" and MaxPooling pool size: \"+str(pool)+\" and dropout: \"+str(dropout2[j])+ \"\\n Fully connected layer with: \"+str(neurons)+\" and dropout: \"+str(dropout3)+\"\\n\")\n",
    "        \n",
    "        (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "        # reshape to be [samples][width][height][pixels]\n",
    "        x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "        \n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        #model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Conv2D(conv3[i], (3,3), activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(tf.keras.layers.Dropout(dropout2[i]))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(x_train, y_train, epochs=5)\n",
    "        evaluation = model.evaluate(x_test, y_test)\n",
    "        print( \"\\nAcurracy is :\" + str(evaluation[1])+\"\\n\")\n",
    "        if evaluation[1] > bestAccuracy[4]:\n",
    "            bestAccuracy = [2, epoch, conv1, conv2, kernel[1], pool[1], dropout1, conv3[i], dropout2[j], neurons, dropout3, evaluation[0], evaluation[1]]\n",
    "            print(\"\\n New Best Accuracy \\n\")\n",
    "        model_json = model.to_json()\n",
    "        \n",
    "        json_file = open(\"model_CNN.json\", \"w\")\n",
    "        json_file.write(model_json)\n",
    "        json_file.close()\n",
    "        model.save_weights(\"model_CNN.h5\")\n",
    "        print(\"Model saved to disk\")\n",
    "        os.getcwd()\n",
    "\n",
    "f=open(\"ConvImproved.txt\",\"a+\")\n",
    "f.write(\"\\n\"+str(bestAccuracy[0])+\" ; \"+str(bestAccuracy[1])+\" ; \"+str(bestAccuracy[2])+\" ; \"+str(bestAccuracy[3])+\" ; \"+str(bestAccuracy[4])+\" ; \"+str(bestAccuracy[5])+\" ; \"+str(bestAccuracy[6])+\" ; \"+str(bestAccuracy[7])+\" ; \"+str(bestAccuracy[8])+\" ; \"+str(bestAccuracy[9])+\" ; \"+str(bestAccuracy[10])+\" ; \"+str(bestAccuracy[11])+\" ; \"+str(bestAccuracy[12]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the code saves the main caracteristics of the network with the best accuracy. Which was: 0.9936 (network with convolution size 32 and 0.3 dropout.\n",
    "\n",
    "Finally, we can produce the code for our final network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Sep 17 17:18:33 2019\n",
    "\n",
    "@author: Andre\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "%-----------------------------------------------------------------------------%\n",
    "%Author: André Barros de Medeiros\n",
    "%Date:09/17/2019\n",
    "%Copyright: free to use, copy, and modify\n",
    "%Description: Convolutional Network to classify MNIST dataset images\n",
    "%Important: Activation Function: RELU \n",
    "%           Optimizer Algorithm: ADAM\n",
    "%           Loss Function: Cross Entropy\n",
    "%\n",
    "%           Mean Loss and Accuracy: see ConvFinal.txt\n",
    "%-----------------------------------------------------------------------------%\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "epoch=5\n",
    "conv1=32\n",
    "conv2=64\n",
    "kernel= [3,3]\n",
    "pool=[2,2]\n",
    "dropout1=0.25\n",
    "conv3=32\n",
    "dropout2=0.3\n",
    "neurons=128\n",
    "dropout3=0.5\n",
    "\n",
    "bestAccuracy=[2,0,0,0,0,0,0,0,0,0,0,0,0.2]\n",
    "\n",
    "\n",
    "print(\"\\nepoch: \" + str(epoch)+\"\\n Convolution 1: \"+str(conv1)+\" with kernel: \"+str(kernel) +\"\\n Convolution 2: \"+str(conv2)+\" with kernel: \"+str(kernel)+\" and MaxPooling pool size: \"+str(pool)+\" and dropout: \"+str(dropout1)+\"\\n Convolution 3: \"+str(conv3)+\" with kernel: \"+str(kernel)+\" and MaxPooling pool size: \"+str(pool)+\" and dropout: \"+str(dropout2)+ \"\\n Fully connected layer with: \"+str(neurons)+\" and dropout: \"+str(dropout3)+\"\\n\")\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][pixels]\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "evaluation = model.evaluate(x_test, y_test)\n",
    "print( \"\\nAcurracy is :\" + str(evaluation[1])+\"\\n\")\n",
    "if evaluation[1] > bestAccuracy[4]:\n",
    "    bestAccuracy = [2, epoch, conv1, conv2, kernel[1], pool[1], dropout1, conv3, dropout2, neurons, dropout3, evaluation[0], evaluation[1]]\n",
    "    print(\"\\n New Best Accuracy \\n\")\n",
    "model_json = model.to_json()\n",
    "\n",
    "json_file = open(\"model_CNN.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "model.save_weights(\"model_CNN.h5\")\n",
    "print(\"Model saved to disk\")\n",
    "os.getcwd()\n",
    "\n",
    "f=open(\"ConvFinal.txt\",\"a+\")\n",
    "f.write(\"\\n\"+str(bestAccuracy[0])+\" ; \"+str(bestAccuracy[1])+\" ; \"+str(bestAccuracy[2])+\" ; \"+str(bestAccuracy[3])+\" ; \"+str(bestAccuracy[4])+\" ; \"+str(bestAccuracy[5])+\" ; \"+str(bestAccuracy[6])+\" ; \"+str(bestAccuracy[7])+\" ; \"+str(bestAccuracy[8])+\" ; \"+str(bestAccuracy[9])+\" ; \"+str(bestAccuracy[10])+\" ; \"+str(bestAccuracy[11])+\" ; \"+str(bestAccuracy[12]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done above, we train the network 4 times and obtain:\n",
    "\n",
    "Average Loss: 0.0244505\n",
    "Average Accuracy: 0.99175\n",
    "\n",
    "Comparing the initial network with our final version, we have a increase of 1% in accuracy, which is very substancial considering we initially only had about 2% of \"room\" to improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
